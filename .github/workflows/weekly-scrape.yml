name: Weekly Data Scrape

on:
  schedule:
    # Run weekly at 2 AM UTC on Sunday
    - cron: "0 2 * * 0"
  workflow_dispatch: # Allow manual triggers
  push:
    branches: [main]
    paths:
      - "src/**"
      - "package.json"
      - ".github/workflows/**"

permissions:
  contents: read
  packages: write
  actions: read
  id-token: write

jobs:
  scrape-and-publish:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
      id-token: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"
          registry-url: "https://registry.npmjs.org"

      - name: Install dependencies
        run: npm ci

      - name: Run data scraping pipeline
        run: |
          npm run build
        env:
          NODE_ENV: production

      - name: Version, generate exports, and publish to NPM (no git push)
        run: |
          # Generate version based on date: YYYY.M.D-HHMM for patch releases
          DATE_VERSION=$(date -u +%Y.%-m.%-d-%H%M)
          echo "Publishing version $DATE_VERSION to NPM"

          # Update package version without auto-commit/tag
          npm version $DATE_VERSION --no-git-tag-version

          # Generate package exports
          npm run generate:exports

          # Enable supply-chain provenance (npm >= 9.5)
          echo "NPM_CONFIG_PROVENANCE=true" >> $GITHUB_ENV

          # Publish to NPM
          npm publish --access public
        env:
          NODE_AUTH_TOKEN: ${{ secrets.NPM_CI_TOKEN }}
